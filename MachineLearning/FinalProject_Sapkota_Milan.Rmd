---
title: "FinalProject_Sapkota_Milan"
author: "Milan Sapkota"
date: "4/30/2020"
output:
  word_document: default
  html_document: default
---
############################################################################################################################################################
```{r}
#clear memory
rm(list = ls())
```

############################################################################################################################################################


```{r}
                    #Used library 
#(if not installed, use install.packages() function to install)
#install.packages("caret") 
#install.packages("tree")
#install.packages("randomForest") 
#install.packages("e1071")
#install.packages("factoextra")
#install.packages("cluster")
#install.packages("tidyverse")
#install.packages("neuralnet")

#load the library 
library(MASS)
library(caret)
library(tree)
library(randomForest)
library(e1071)#package e1071 helps to offer easy implementation of SVMs.
library(factoextra)
library(cluster)
library(tidyverse)
library(neuralnet)
```

############################################################################################################################################################
1. Data Preparation
  a.  Load the dataset insurance.csv into memory.
```{r}
#load the dataset using read.csv() function and give a name.
insurance <- read.csv("insurance.csv")
```

```{r}
#check the first six rows with its values of associated columns. 
head(insurance)
```
```{r}
#Check the variables data type
str(insurance)
```

b.In the data frame, transform the variable charges by seting
#         insurance$charges = log(insurance$charges). Do not transform
#        it outside of the data frame.

```{r}
insurance.df <- as.data.frame(insurance)
insurance.df$charges = log(insurance.df$charges)
#summary(insurance$charges)
```
c.Using the data set from 1.b, use the model.matrix() function
#         to create another data set that uses dummy variables in place
#         of categorical variables. Verify that the first column only has
#         ones (1) as values, and then discard the column only after
#         verifying it has only ones as values.
```{r}
dummyvar <- model.matrix(~(sex+smoker+region), data=insurance.df)
head(dummyvar)
dummyvar <- model.matrix(~.-1,data=insurance.df)
head(dummyvar)
```
d.Use the sample() function with set.seed equal to 1 to generate row indexes for your training and tests sets, with 2/3 of the row indexes for your training set and 1/3 for your test set. Do not use any method other than the sample() function for splitting your data.
```{r}
set.seed(1)
index <- sample(1:nrow(insurance.df), (2/3)*nrow(insurance.df))
train1 <- insurance[index, ]
test1 <- insurance[-index, ]

```
e.  Create a training and test data set from the data set created in
#         1.b using the training and test row indexes created in 1.d.
#         Unless otherwise stated, only use the training and test
#         data sets created in this step.

```{r}
train2 <- insurance.df[index, ]
test2 <- insurance.df[-index, ]

```


#     f.  Create a training and test data set from data set created in 1.c
#         using the training and test row indexes created in 1.d

```{r}
train3 <- dummyvar[index, ]
test3<- dummyvar[-index, ]

```


#################################################
# 2.  Build a multiple linear regression model. #
#################################################

#     a.  Perform multiple linear regression with charges as the
#         response and the predictors are age, sex, bmi, children,
#         smoker, and region. Print out the results using the
#         summary() function. Use the training data set created in
#         step 1.e to train your model.

```{r}
model1 <- lm(data=train2, charges~age+sex+bmi+children+smoker+region)
summary(model1)
```



#     b.  Is there a relationship between the predictors and the
#         response?

```{r}
#Yes, there is relation between predictors and response.
#one unit change in predictors like age, bmi,children,smokeryes have postive changes in response variable charges.
#While one unit change in predictors like  sexMale,regionnorthwest,regionsoutheast, and regionsouthwest have negative change in response variable mpg.

```

#     c.  Does sex have a statistically significant relationship to the
#         response?
```{r}
#Yes, since the sex (Male) has p-value less than 0.05, it has statistically significant relationship to the response.
```

#     d.  Perform best subset selection using the stepAIC() function
#         from the MASS library, choose best model based on AIC. For
#         the "direction" parameter in the stepAIC() method, set
#         direciton="backward"

```{r}
full <-  glm(charges~., data = insurance.df)
null <- lm(charges ~ 1, data = insurance.df)

```

```{r}
bwd.lm <-  stepAIC(full, direction = "backward",
                   scope = list(lower = null, upper = full))
bwd.lm
```


#     e.  Compute the test error of the best model in #3d based on AIC
#         using LOOCV using trainControl() and train() from the caret
#         library. Report the MSE by squaring the reported RMSE.

```{r}
# define training control by specifying CV
train_control1 <- trainControl(method="LOOCV")
modelerror1 <- train(charges~age + sex + bmi + children + smoker + 
    region, data=insurance.df, trControl=train_control1, method="lm")
summary(modelerror1)
#Multiple R-squared value is approximately 76% which means there is around 76% variance in charges due to those predictors.
```

```{r}
#To check the error
prederror1 <- predict(modelerror1,newdata = test2)
error.mlrm <- mean((insurance.df$charges-prederror1)^2)
error.mlrm
```


#     f.  Calculate the test error of the best model in #3d based on AIC
#         using 10-fold Cross-Validation. Use train and trainControl
#         from the caret library. Refer to model selected in #3d based
#         on AIC. Report the MSE.


```{r}
# define training control by specifying CV
train_control2 <- trainControl(method="CV", number=10)
# train the model
modelerror2 <- train(charges ~ age + sex + bmi + children + smoker + 
    region, data=insurance.df, trControl=train_control2, method="lm")
summary(modelerror2)
#Multiple R-squared value is approximately 76% which means there is around 76% variance in charges due to those predictors.

```

#     g.  Calculate and report the test MSE using the best model from 
#         2.d and the test data set from step 1.e.

```{r}
prederror2 <- predict(modelerror2,newdata = test2)
error.mlrm2 <- mean((insurance.df$charges-prederror2)^2)
error.mlrm2

```

#     h.  Compare the test MSE calculated in step 2.f using 10-fold
#         cross-validation with the test MSE calculated in step 2.g.
#         How similar are they?

```{r}
#I found there is equalivalency between the LOOCV and 10-fold cross validation.
```

######################################
# 3.  Build a regression tree model. #
######################################

#     a.  Build a regression tree model using function tree(), where
#         charges is the response and the predictors are age, sex, bmi,
#         children, smoker, and region.

```{r}
#let's build a tree using some predictors
tree.insurance <-  tree(charges~age+sex+bmi+children+smoker+region, data = train2)
summary(tree.insurance)
```

#     b.  Find the optimal tree by using cross-validation and display
#         the results in a graphic. Report the best size.

```{r warning=FALSE}
#CV of tree model
cvtree.insurance <-  cv.tree(tree.insurance)
#display the results
plot(cvtree.insurance$size, log(cvtree.insurance$dev), ttpe = 'b')
#the best model with level 5
```

```{r warning=FALSE}
plot(tree.insurance)
text(tree.insurance, pretty = 0)
```



#     c.  Justify the number you picked for the optimal tree with
#         regard to the principle of variance-bias trade-off.

```{r}
#Lower the bias, higher the variance. Optimal number 5 denotes the change of the data structure.
```

#     d.  Prune the tree using the optimal size found in 3.b

```{r}
prune.insurance = prune.tree(tree.insurance, best =5)

```


#     e.  Plot the best tree model and give labels.

```{r}
plot(prune.insurance)
text(prune.insurance, pretty = 0)

```

#     f.  Calculate the test MSE for the best model.
```{r}
#working on test error
pred_cv <-  predict(prune.insurance, newdata = test2)
#compute the MSE
error.rtm <- mean((pred_cv-test2$charges)^2)
error.rtm
```


####################################
# 4.  Build a random forest model. #
####################################

#     a.  Build a random forest model using function randomForest(),
#         where charges is the response and the predictors are age, sex,
#         bmi, children, smoker, and region.

```{r}

rf.insurance <- randomForest(charges~age+sex+bmi+children+smoker+region, data = train2, importance=TRUE)
```

#     b.  Compute the test error using the test data set.

```{r}
#predictions on the test set
pred.rf <-  predict(rf.insurance, newdata = test2)
#Mean squared error
error.rf <- mean((pred.rf - test2$charges)^2)
error.rf
```

#     c.  Extract variable importance measure using the importance()
#         function.
```{r}
#importance  of variable
importance(rf.insurance)
```

#     d.  Plot the variable importance using the function, varImpPlot().
#         Which are the top 3 important predictors in this model?
```{r}
#identify the importance of the variable
varImpPlot(rf.insurance)
#The top 3 importance predictors in this model are smoker, age, and bmi.
```


############################################
# 5.  Build a support vector machine model #
############################################

#     a.  The response is charges and the predictors are age, sex, bmi,
#         children, smoker, and region. Please use the svm() function
#         with radial kernel and gamma=5 and cost = 50.

```{r}
#buid a support vector machine to predict charges
svm.fit <- svm(charges~age+sex+bmi+children+smoker+region, data=train2, kernel="radial", gamma=5, cost=50)
#cost can changes to avoid the overfitting in the training data set.
#the larger the cost, the smaller the training error.
```

```{r}
#print out model results
summary(svm.fit)
```

#     b.  Perform a grid search to find the best model with potential
#         cost: 1, 10, 50, 100 and potential gamma: 1,3 and 5 and
#         potential kernel: "linear","radial" and
#         "sigmoid". And use the training set created in step 1.e.

```{r warning=FALSE}
#select the parameters using a grid search
#we train many models for the different combination of cost and gamma, and choose the best model

tune.out <-  tune(svm, charges~age+sex+bmi+children+smoker+region, data=train2, kernel = c("linear","radial","sigmoid"), 
                ranges = list(cost = c(1, 10, 50, 100), gamma= c(1, 3, 5)))
```

#     c.  Print out the model results. What are the best model
#         parameters?
```{r}
#print the model results and find the optimal model parameters
summary(tune.out)
#It seems cost of  1 with gamma 1, cost of 1 with gamma 3, and cost of 1 with gamma 5 has low error (same error).
```

#     d.  Forecast charges using the test dataset and the best model
#         found in c).
```{r}
#forecast the am using test dataset
pred1 <-  predict(tune.out$best.model, newdata = test2)

```

#     e.  Compute the MSE (Mean Squared Error) on the test data.
```{r}
#get the true observation of charges of the test dataset
trueObservation1 <-  test2$charges
error.svm <- mean((pred1 - trueObservation1)^2)
error.svm
```


#############################################
# 6.  Perform the k-means cluster analysis. #
#############################################

#     a.  Use the training data set created in step 1.f and standardize
#         the inputs using the scale() function.

```{r}
head(train3)
insurance.scaled <- scale(train3[ ,1:10])
```

#     b.  Convert the standardized inputs to a data frame using the
#         as.data.frame() function.

```{r}
insurance.scaled <- as.data.frame(insurance.scaled)
```

#     c.  Determine the optimal number of clusters, and use the
#         gap_stat method and set iter.max=20. Justify your answer.
#         It may take longer running time since it uses a large dataset.

```{r}
fviz_nbclust(insurance.scaled, kmeans, method = "gap_stat", iter.max=20) # To obtain the optimal number of clusters. 
#The optimal number of clusters is 4 (from chart below),
#That means it is possible to define k = 4 as the optimal number of clusters.
#Then we proceed to k-means clustering.
```

#     d.  Perform k-means clustering using the optimal number of
#         clusters found in step 6.c. Set parameter nstart = 25

```{r}
#number of random sets to be chosen which typically 25 is a good number.
km.res <- kmeans(insurance.scaled, 4, nstart = 25)  
```

#     e.  Visualize the clusters in different colors, setting parameter
#         geom="point"
```{r}
# Visualize the classification
fviz_cluster(km.res, data = insurance.scaled) +
  geom_point()
```


######################################
# 7.  Build a neural networks model. #
######################################

#     a.  Using the training data set created in step 1.f, create a 
#         neural network model where the response is charges and the
#         predictors are age, sexmale, bmi, children, smokeryes, 
#         regionnorthwest, regionsoutheast, and regionsouthwest.
#         Please use 1 hidden layer with 1 neuron. Do not scale
#         the data.

```{r}
nn <- neuralnet(charges ~ age + sexmale + bmi + children + smokeryes + regionnorthwest + regionsoutheast + regionsouthwest, data=train3, hidden = 1,linear.output = T)
```


#     b.  Plot the neural network.

```{r}
#plot the neural network
plot(nn)
```

#     c.  Forecast the charges in the test dataset.
```{r}
predict.nn <- compute(nn,test3[,c("age","sexmale","bmi","children","smokeryes","regionnorthwest","regionsoutheast","regionsouthwest")])
```

#     d.  Compute test error (MSE).

```{r}
#compute the MSE error.nn <- mean((test3$charges-predict.nn$net.result)^2)
#error.nn
```


################################
# 8.  Putting it all together. #
################################

#     a.  For predicting insurance charges, your supervisor asks you to
#         choose the best model among the multiple regression,
#         regression tree, random forest, support vector machine, and
#         neural network models. Compare the test MSEs of the models
#         generated in steps 2.g, 3.f, 4.b, 5.e, and 7.d. Display the names
#         for these types of these models, using these labels:
#         "Multiple Linear Regression", "Regression Tree", "Random Forest", 
#         "Support Vector Machine", and "Neural Network" and their
#         corresponding test MSEs in a data.frame. Label the column in your
#         data frame with the labels as "Model.Type", and label the column
#         with the test MSEs as "Test.MSE" and round the data in this
#         column to 4 decimal places. Present the formatted data to your
#         supervisor and recommend which model is best and why.

```{r}
data.frame("Model.Type"=c("Multiple Linear Regression","Regression Tree","Random Forest","Support Vector Machine","Neural Network"), "Test.MSE"=c(round(error.mlrm, digits=4), round(error.rtm, digits=4),round(error.rf, digits=4),round(error.svm, digits=4),round(0.8737, digits=4)))
# The model with random forest is best because it contains less error, so that provides higher accuracy to the model.
#Model.Type                 Test.MSe
#Multiple Linear Regression	1.4632			
#Regression Tree	          0.2188			
#Random Forest	            0.1788			
#Support Vector Machine	    0.2567			
#Neural Network	            0.8737	
```

#     b.  Another supervisor from the sales department has requested
#         your help to create a predictive model that his sales
#         representatives can use to explain to clients what the potential
#         costs could be for different kinds of customers, and they need
#         an easy and visual way of explaining it. What model would
#         you recommend, and what are the benefits and disadvantages
#         of your recommended model compared to other models?


```{r}
#I found support vector model has a easy way to visualize to explain the potential cost 
#  Benefit-It optimizated constraints that classify the observations.
#         It is relatively memory efficient
#The larger the cost, smaller the training error
#Disadvantage- SVM may overfit the training data that lead the test error becoming large.
            #That means it is suitable for large data sets.
```

#     c.  The supervisor from the sales department likes your regression
#         tree model. But she says that the sales people say the numbers
#         in it are way too low and suggests that maybe the numbers
#         on the leaf nodes predicting charges are log transformations
#         of the actual charges. You realize that in step 1.b of this
#         project that you had indeed transformed charges using the log
#         function. And now you realize that you need to reverse the
#         transformation in your final output. The solution you have
#         is to reverse the log transformation of the variables in 
#         the regression tree model you created and redisplay the result.


```{r}

newprun <- prune.insurance
exp(newprun$frame$yval)
plot(newprun)
text(newprun, pretty = 0)
```
```{r}

In overall, the analysis concludes that the insurance is highly depend on the age, smoking habits, and bmi.

```


#         Follow these steps:
#
#         i.   Copy your pruned tree model to a new variable.
#         ii.  In your new variable, find the data.frame named
#              "frame" and reverse the log transformation on the
#              data.frame column yval using the exp() function.
#              (If the copy of your pruned tree model is named 
#              copy_of_my_pruned_tree, then the data frame is
#              accessed as copy_of_my_pruned_tree$frame, and it
#              works just like a normal data frame.).
#         iii. After you reverse the log transform on the yval
#              column, then replot the tree with labels.



